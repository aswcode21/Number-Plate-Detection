{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Downloads\\Licence-Plate-Detection-using-YOLO-V8\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule path 'thirdparty/fast-reid': checked out '1b9799f601a0302ef015677e7a157eda0a4f9268'\n",
      "Submodule path 'thirdparty/mmdetection': checked out '3e902c3afc62693a71d672edab9b22e35f7d4776'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'deep_sort_pytorch'...\n",
      "Submodule 'thirdparty/fast-reid' (https://github.com/JDAI-CV/fast-reid.git) registered for path 'thirdparty/fast-reid'\n",
      "Submodule 'thirdparty/mmdetection' (https://github.com/open-mmlab/mmdetection.git) registered for path 'thirdparty/mmdetection'\n",
      "Cloning into 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch/thirdparty/fast-reid'...\n",
      "Cloning into 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch/thirdparty/mmdetection'...\n"
     ]
    }
   ],
   "source": [
    "!git clone --recurse-submodules https://github.com/ZQPei/deep_sort_pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Downloads\\Licence-Plate-Detection-using-YOLO-V8\\deep_sort_pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Downloads\\Licence-Plate-Detection-using-YOLO-V8\\deep_sort_pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_pytorch.utils.parser import get_config\n",
    "from deep_sort_pytorch.deep_sort import DeepSort\n",
    "from deep_sort_pytorch.deep_sort.sort.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "                                              0.0/144.7 kB ? eta -:--:--\n",
      "     -----                                 20.5/144.7 kB 640.0 kB/s eta 0:00:01\n",
      "     ----------                            41.0/144.7 kB 487.6 kB/s eta 0:00:01\n",
      "     ---------------                       61.4/144.7 kB 544.7 kB/s eta 0:00:01\n",
      "     --------------------                  81.9/144.7 kB 508.4 kB/s eta 0:00:01\n",
      "     -------------------------            102.4/144.7 kB 535.8 kB/s eta 0:00:01\n",
      "     -------------------------            102.4/144.7 kB 535.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 144.7/144.7 kB 537.8 kB/s eta 0:00:00\n",
      "Installing collected packages: pyyaml\n",
      "Successfully installed pyyaml-6.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_pytorch.deep_sort.deep_sort import DeepSort\n",
    "deep_sort_weights = 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from deep_sort_pytorch.deep_sort import DeepSort\n",
    "from deep_sort_pytorch.utils.parser import get_config\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Step 2: Load the Deep SORT configuration\n",
    "cfg = get_config()\n",
    "cfg.merge_from_file('C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch/configs/deep_sort.yaml')\n",
    "deepsort = DeepSort(cfg.DEEPSORT.WEIGHTS, \n",
    "                    max_dist=cfg.DEEPSORT.MAX_DIST, \n",
    "                    max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n",
    "                    max_age=cfg.DEEPSORT.MAX_AGE, \n",
    "                    n_init=cfg.DEEPSORT.N_INIT, \n",
    "                    nn_budget=cfg.DEEPSORT.NN_BUDGET,\n",
    "                    use_cuda=True)\n",
    "\n",
    "# Step 3: Initialize the video capture\n",
    "cap = cv2.VideoCapture('C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/video_path')\n",
    "\n",
    "# Step 4: Process the video frame by frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Step 5: Detect objects using the YOLOv8 model\n",
    "    results = model(frame)\n",
    "    detections = results.pred[0]\n",
    "\n",
    "    # Step 6: Update the Deep SORT tracker\n",
    "    tracks = deepsort.update(detections.cpu())\n",
    "\n",
    "    # Step 7: Draw the tracked objects on the frame\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue\n",
    "        bbox = track.to_tlbr()\n",
    "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 255, 255), 2)\n",
    "        cv2.putText(frame, str(track.track_id), (int(bbox[0]), int(bbox[1])), 0, 5e-3 * 200, (0, 255, 0), 2)\n",
    "\n",
    "    # Step 8: Display the output\n",
    "    cv2.imshow('Deep SORT Tracking', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Step 9: Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/runs/detect/train/weights/best.pt')\n",
    "\n",
    "\n",
    "# Open a video file or a webcam feed\n",
    "video_path = 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/video_path'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer\n",
    "output_path = 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 files\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Initialize Deep SORT\n",
    "cfg_deepsort = get_config()\n",
    "cfg_deepsort.merge_from_file(\"deep_sort_pytorch/configs/deep_sort.yaml\")\n",
    "deepsort = DeepSort(\n",
    "    cfg_deepsort.DEEPSORT.WEIGHTS,\n",
    "    max_dist=cfg_deepsort.DEEPSORT.MAX_DIST,\n",
    "    min_confidence=cfg_deepsort.DEEPSORT.MIN_CONFIDENCE,\n",
    "    nms_max_overlap=cfg_deepsort.DEEPSORT.NMS_MAX_OVERLAP,\n",
    "    max_iou_distance=cfg_deepsort.DEEPSORT.MAX_IOU_DISTANCE,\n",
    "    max_age=cfg_deepsort.DEEPSORT.MAX_AGE,\n",
    "    n_init=cfg_deepsort.DEEPSORT.N_INIT,\n",
    "    nn_budget=cfg_deepsort.DEEPSORT.NN_BUDGET,\n",
    "    use_cuda=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 detection\n",
    "    results = model(frame)\n",
    "    detections = results.xywh[0]  # Extract detection results (x_center, y_center, width, height, confidence, class)\n",
    "    \n",
    "    # Prepare detection data for Deep SORT\n",
    "    xywhs = detections[:, 0:4]\n",
    "    confs = detections[:, 4]\n",
    "    clss = detections[:, 5]\n",
    "\n",
    "    # Run Deep SORT tracking\n",
    "    outputs = deepsort.update(xywhs.cpu(), confs.cpu(), frame)\n",
    "\n",
    "    # Draw boxes for visualization\n",
    "    for output in outputs:\n",
    "        x1, y1, x2, y2, track_id = output[:5]\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deep_sort_weights = 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)\n",
    "# Define the video path\n",
    "video_path = 'C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/video_path'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"C:/Users/HP/Downloads/Licence-Plate-Detection-using-YOLO-V8/runs/detect/train/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results = model(frame, device=0, classes=0, conf=0.8)\n",
    "\n",
    "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bbox outputs\n",
    "            probs = result.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                #print(\"Class:\", class_name)\n",
    "\n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "       \n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        #cv2.imshow(\"Video\", og_frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
